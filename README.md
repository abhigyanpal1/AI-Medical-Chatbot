# Neural Network from Scratch

## Project Overview

This project implements a simple neural network from scratch using Python. The goal of the project is to gain a deeper understanding of how neural networks work under the hood by manually implementing essential components such as forward propagation, backpropagation, and gradient descent without the use of deep learning libraries like TensorFlow or PyTorch.

## Features

- Fully connected feedforward neural network
- Customizable number of layers and neurons per layer
- Manual implementation of:
  - Activation functions (e.g., Sigmoid, ReLU, Tanh)
  - Loss functions (e.g., Mean Squared Error, Cross-Entropy)
  - Gradient Descent for optimizing weights
- Supports batch training and mini-batch gradient descent
- Can handle classification and regression tasks
- Train and test on custom datasets or common datasets like MNIST

## Installation

To get started with this project, you will need Python 3.x installed on your machine. Clone this repository and install the required dependencies.


